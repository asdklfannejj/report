# report.py â€” ì±„íŒ…í˜• ë³´ê³ ì„œ ë©”ì´ì»¤ / Plotly / Ollama ì„¤ëª… / ì¶”ì²œ í”Œëœ(ì‚¬ëŒ ì¹œí™”í˜•+í¸ì§‘) / PPTÂ·WordÂ·Excel
# ìš”êµ¬ íŒ¨í‚¤ì§€(requirements.txt):
# streamlit, pandas, numpy, plotly, kaleido, pdfplumber, openpyxl, xlsxwriter, python-pptx, python-docx, requests
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.figure_factory as ff
import pdfplumber
import io, zipfile, requests, os
from datetime import datetime

from pptx import Presentation
from pptx.util import Inches as PptxInches, Pt
from pptx.enum.text import PP_ALIGN

from docx import Document
from docx.shared import Inches as DocxInches

from matplotlib import font_manager, rcParams
import matplotlib.pyplot as plt

# ---------- í•œê¸€ í°íŠ¸ ----------
FONT_PATH = os.path.join(os.path.dirname(__file__), "fonts", "MaruBuri-Regular.ttf")
if os.path.exists(FONT_PATH):
    try:
        font_manager.fontManager.addfont(FONT_PATH)
        rcParams["font.family"] = "MaruBuri"
    except Exception:
        rcParams["font.family"] = ["Malgun Gothic", "AppleGothic", "Noto Sans CJK KR", "NanumGothic", "DejaVu Sans"]
else:
    rcParams["font.family"] = ["Malgun Gothic", "AppleGothic", "Noto Sans CJK KR", "NanumGothic", "DejaVu Sans"]
rcParams["axes.unicode_minus"] = False
PLOTLY_FONT_FAMILY = "MaruBuri, NanumGothic, 'Malgun Gothic', AppleGothic, 'Noto Sans CJK KR', 'DejaVu Sans', sans-serif"

# ---------- Plotly ìŠ¤íƒ€ì¼ ----------
def _style_plotly(fig, title=None):
    fig.update_layout(
        template="plotly_white",
        title=title if title else fig.layout.title.text,
        title_x=0.5,
        title_font_size=18,
        font=dict(family=PLOTLY_FONT_FAMILY),
        margin=dict(l=50, r=30, t=90, b=50),
    )
    fig.update_xaxes(title_standoff=8, automargin=True)
    fig.update_yaxes(title_standoff=12, automargin=True)
    return fig

def _fig_to_png_bytes(fig):
    try:
        return fig.to_image(format="png", scale=2)  # kaleido í•„ìš”
    except Exception:
        if not st.session_state.get("_warn_kaleido", False):
            st.session_state["_warn_kaleido"] = True
            st.info("PNG ë‚´ë³´ë‚´ê¸°ìš©ìœ¼ë¡œ `kaleido`ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì¹˜ê°€ ì—†ìœ¼ë©´ Matplotlibë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        return None

# ---------- KDE(ì„ íƒ; scipy ìˆìœ¼ë©´ ì‚¬ìš©) ----------
def _try_kde(values, n_points=200):
    try:
        from numpy import isfinite, linspace
        from scipy.stats import gaussian_kde
        vals = np.asarray(values, dtype=float)
        vals = vals[isfinite(vals)]
        if vals.size < 2:
            return None, None
        kde = gaussian_kde(vals)
        xs = linspace(float(vals.min()), float(vals.max()), n_points)
        ys = kde(xs)
        return xs, ys
    except Exception:
        return None, None

# ---------- Matplotlib ëŒ€ì²´ PNG ----------
def _mpl_hist_png(series, title, xlabel, bins=20):
    buf = io.BytesIO()
    fig, ax = plt.subplots(figsize=(6.4, 4.2))
    ax.hist(series.dropna().values, bins=bins, edgecolor="white", alpha=0.9)
    ax.set_title(title); ax.set_xlabel(xlabel); ax.set_ylabel("ê°œìˆ˜")
    fig.tight_layout(); fig.savefig(buf, format="png", dpi=200); plt.close(fig)
    return buf.getvalue()

def _mpl_corr_png(corr_df, title):
    buf = io.BytesIO()
    fig, ax = plt.subplots(figsize=(6.4, 5.0))
    cax = ax.imshow(corr_df.values, cmap="RdBu", vmin=-1, vmax=1)
    ax.set_xticks(np.arange(len(corr_df.columns))); ax.set_yticks(np.arange(len(corr_df.columns)))
    ax.set_xticklabels(corr_df.columns, rotation=90); ax.set_yticklabels(corr_df.columns)
    ax.set_title(title); fig.colorbar(cax); fig.tight_layout(); fig.savefig(buf, format="png", dpi=200); plt.close(fig)
    return buf.getvalue()

# ---------- Ollama ----------
@st.cache_data(show_spinner=False, ttl=600)
def _ollama_generate(base_url: str, model: str, prompt: str, timeout: int = 90) -> str:
    try:
        url = base_url.rstrip("/") + "/api/generate"
        payload = {"model": model, "prompt": prompt, "stream": False}
        r = requests.post(url, json=payload, timeout=timeout)
        r.raise_for_status()
        data = r.json()
        return data.get("response") or data.get("text") or ""
    except Exception as e:
        return f"(ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e})"

# ---------- ì¶”ì²œ í”Œëœ ----------
def infer_schema(df: pd.DataFrame):
    date_cols, numeric_cols, cat_cols = [], [], []
    for c in df.columns:
        s = df[c]
        if pd.api.types.is_numeric_dtype(s):
            numeric_cols.append(c)
        else:
            try:
                pd.to_datetime(s, errors="raise", infer_datetime_format=True)
                date_cols.append(c)
            except Exception:
                if s.dropna().nunique() <= max(20, int(len(s) * 0.05)):
                    cat_cols.append(c)
    return date_cols, numeric_cols, cat_cols

def recommend_plan(df: pd.DataFrame) -> dict:
    date_cols, numeric_cols, cat_cols = infer_schema(df)
    plan = {"timeseries": [], "numeric_dists": [], "categoricals": [], "correlation": False}
    if date_cols and numeric_cols:
        for n in numeric_cols[:3]:
            plan["timeseries"].append((date_cols[0], n))
    plan["numeric_dists"] = numeric_cols[:5]
    plan["categoricals"] = cat_cols[:3]
    plan["correlation"] = len(numeric_cols) >= 2
    return plan

# --- ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ì¶”ì²œ í”Œëœ ë Œë”ëŸ¬ & í¸ì§‘ê¸° ---
def _humanize_plan(plan: dict) -> str:
    ts = plan.get("timeseries", [])
    nd = plan.get("numeric_dists", [])
    ct = plan.get("categoricals", [])
    cor = plan.get("correlation", False)

    md = []
    md.append("### ğŸ” ì¶”ì²œ ë³´ê³ ì„œ í”Œëœ (ìš”ì•½)")
    if ts:
        md.append(f"- â± **ì‹œê³„ì—´**: ë‚ ì§œ ê¸°ì¤€ ì§€í‘œ {len(ts)}ê°œ")
    if nd:
        md.append(f"- ğŸ“ˆ **ìˆ«ì ë¶„í¬**: {len(nd)}ê°œ ì§€í‘œ")
    if ct:
        md.append(f"- ğŸ§© **ë²”ì£¼ ë¶„í¬**: {len(ct)}ê°œ ì»¬ëŸ¼")
    md.append(f"- ğŸ”— **ìƒê´€ê´€ê³„ ë¶„ì„**: {'ì‹¤í–‰ ê¶Œì¥' if cor else 'ë¶ˆí•„ìš”'}")
    md.append("")

    if ts:
        md.append("**ì‹œê³„ì—´ í›„ë³´**")
        md.append("| ë‚ ì§œì—´ | ì§€í‘œ |")
        md.append("|---|---|")
        for dcol, ncol in ts:
            md.append(f"| {dcol} | {ncol} |")
        md.append("")

    if nd:
        md.append("**ìˆ«ìí˜• ë¶„í¬ í›„ë³´**")
        md.append(", ".join([f"`{c}`" for c in nd]))
        md.append("")

    if ct:
        md.append("**ë²”ì£¼í˜• ë¶„í¬ í›„ë³´**")
        md.append(", ".join([f"`{c}`" for c in ct]))
        md.append("")

    if not (ts or nd or ct):
        md.append("> ğŸ¤” ìœ ì˜ë¯¸í•œ ì¶”ì²œì´ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ 1ê°œ ì´ìƒì˜ ìˆ«ìí˜•/ë‚ ì§œí˜• ì»¬ëŸ¼ì´ í•„ìš”í•´ìš”.")
    return "\n".join(md)

def _plan_editor(plan: dict, key_prefix: str):
    """
    ì¶”ì²œ í”Œëœì„ ì‚¬ìš©ìê°€ ë°”ë¡œ ë‹¤ë“¬ì„ ìˆ˜ ìˆëŠ” ê°„ë‹¨ í¸ì§‘ê¸°(ì²´í¬/ì„ íƒ).
    key_prefixë¥¼ ë¶™ì—¬ì„œ ìœ„ì ¯ í‚¤ ì¤‘ë³µ ë°©ì§€.
    """
    with st.expander("ğŸ›  ì¶”ì²œ í”Œëœ í¸ì§‘", expanded=False):
        # ì‹œê³„ì—´ ì²´í¬ë°•ìŠ¤
        ts = plan.get("timeseries", [])
        if ts:
            st.markdown("**â± ì‹œê³„ì—´ í¬í•¨ ì—¬ë¶€**")
            new_ts = []
            for (dcol, ncol) in ts:
                on = st.checkbox(
                    f"{dcol} â†’ {ncol}",
                    value=True,
                    key=f"{key_prefix}_ts_{dcol}_{ncol}"
                )
                if on:
                    new_ts.append((dcol, ncol))
            plan["timeseries"] = new_ts

        # ìˆ«ìí˜• ë©€í‹°ì…€ë ‰íŠ¸
        nd = plan.get("numeric_dists", [])
        if nd:
            st.markdown("**ğŸ“ˆ ìˆ«ìí˜• ë¶„í¬(ë©€í‹° ì„ íƒ)**")
            selected_nd = st.multiselect(
                "í¬í•¨í•  ì§€í‘œ",
                options=nd,
                default=nd,
                key=f"{key_prefix}_nd_select"
            )
            plan["numeric_dists"] = selected_nd

        # ë²”ì£¼í˜• ë©€í‹°ì…€ë ‰íŠ¸
        ct = plan.get("categoricals", [])
        if ct:
            st.markdown("**ğŸ§© ë²”ì£¼í˜• ë¶„í¬(ë©€í‹° ì„ íƒ)**")
            selected_ct = st.multiselect(
                "í¬í•¨í•  ì»¬ëŸ¼",
                options=ct,
                default=ct,
                key=f"{key_prefix}_ct_select"
            )
            plan["categoricals"] = selected_ct

        # ìƒê´€ê´€ê³„ ì²´í¬ë°•ìŠ¤
        plan["correlation"] = st.checkbox(
            "ğŸ”— ìƒê´€ê´€ê³„ ë¶„ì„ í¬í•¨",
            value=plan.get("correlation", False),
            key=f"{key_prefix}_cor_on"
        )

        st.info("ì„¤ì •ì´ ì¦‰ì‹œ ë°˜ì˜ë©ë‹ˆë‹¤. â€˜ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±â€™ ì‹œ í¸ì§‘ëœ í”Œëœì´ ì‚¬ìš©ë©ë‹ˆë‹¤.")
    return plan

# ---------- UI: ì‚¬ì´ë“œë°” ----------
st.title("âœ¨ ì±„íŒ…í˜• ì´ë²¤íŠ¸ ê²°ê³¼ë³´ê³ ì„œ ë©”ì´ì»¤ (Ollama ì„¤ëª… í¬í•¨)")

with st.sidebar:
    st.header("ğŸ“¡ Ollama ì„¤ì •")
    use_ollama = st.checkbox("ê·¸ë˜í”„/ìš”ì•½ ìë™ ì„¤ëª… ìƒì„±", value=False)
    ollama_model = st.text_input("ëª¨ë¸", value="llama3.1")
    ollama_base = st.text_input("ì„œë²„ URL", value="http://127.0.0.1:11500")
    st.caption("ë¡œì»¬ ë˜ëŠ” ì›ê²© Ollama ì„œë²„ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. (ì˜ˆ: llama3.1, qwen2.5:7b-instruct)")

    st.header("ğŸ“Š ì°¨íŠ¸ ì˜µì…˜")
    BIN_MODE = st.radio("ë¹ˆ êµ¬ë¶„", ["ìë™", "ê°œìˆ˜ ì§€ì •", "ê°„ê²© ì§€ì •"], index=0, horizontal=True)
    nbins = st.slider("ë¹ˆ ê°œìˆ˜", 5, 100, 20) if BIN_MODE == "ê°œìˆ˜ ì§€ì •" else None
    binsize = st.number_input("ë¹ˆ ê°„ê²©", min_value=0.0, value=0.0, step=1.0) if BIN_MODE == "ê°„ê²© ì§€ì •" else None
    bargap = st.slider("ë§‰ëŒ€ ê°„ê²©", 0.00, 0.50, 0.25, 0.01)
    show_kde = st.checkbox("ë°€ë„ ê³¡ì„ (KDE)", value=True)
    y_scale = st.selectbox("ì„¸ë¡œì¶•", ["count", "percent", "probability density"], index=0)

# ---------- ì—…ë¡œë“œ ----------
uploaded_files = st.file_uploader("ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ (Excel ë˜ëŠ” PDF)", type=["xlsx","xls","pdf"], accept_multiple_files=True)

# ---------- ì±„íŒ… ìƒíƒœ ----------
if "messages" not in st.session_state:
    st.session_state.messages = []
if "prefs" not in st.session_state:
    st.session_state.prefs = {
        "audience": "ì¼ë°˜",
        "tone": "ê°„ê²°",
        "outputs": {"md": True, "excel": True, "ppt": True, "docx": True},
        "sections": {"overview": True, "numeric": True, "categorical": True, "timeseries": True, "correlation": True},
        "kpis": [],
    }

def chat_bot_reply(user_text):
    u = user_text.strip().lower()
    prefs = st.session_state.prefs
    msg = ""
    if u.startswith("/audience"):
        if "ì„ì›" in user_text: prefs["audience"] = "ì„ì›"; msg = "ëŒ€ìƒ: ì„ì›ìš©ìœ¼ë¡œ ì„¤ì •í–ˆì–´ìš”."
        elif "ì‹¤ë¬´" in user_text: prefs["audience"] = "ì‹¤ë¬´"; msg = "ëŒ€ìƒ: ì‹¤ë¬´ìš©ìœ¼ë¡œ ì„¤ì •í–ˆì–´ìš”."
        else: msg = "ëŒ€ìƒì„ 'ì¼ë°˜/ì„ì›/ì‹¤ë¬´' ì¤‘ì—ì„œ ë§ì”€í•´ ì£¼ì„¸ìš”."
    elif u.startswith("/tone"):
        if "ìƒì„¸" in user_text: prefs["tone"] = "ìƒì„¸"; msg = "ì–´ì¡°: ìƒì„¸ ì„¤ëª…ìœ¼ë¡œ ì„¤ì •í–ˆì–´ìš”."
        else: prefs["tone"] = "ê°„ê²°"; msg = "ì–´ì¡°: ê°„ê²°í•œ ìš”ì•½ìœ¼ë¡œ ì„¤ì •í–ˆì–´ìš”."
    elif u.startswith("/out"):
        prefs["outputs"] = {"md": "md" in u or "markdown" in u,
                            "excel": "excel" in u or "xlsx" in u,
                            "ppt": "ppt" in u or "íŒŒì›Œí¬ì¸íŠ¸" in u or "ìŠ¬ë¼ì´ë“œ" in u,
                            "docx": "word" in u or "docx" in u or "ì›Œë“œ" in u}
        msg = f"ì‚°ì¶œë¬¼ ì„¤ì •: {prefs['outputs']}"
    elif u.startswith("/kpi"):
        cols = [c.strip() for c in user_text.split(" ",1)[1].split(",")] if " " in user_text else []
        prefs["kpis"] = [c for c in cols if c]
        msg = f"KPI ì»¬ëŸ¼ ì§€ì •: {prefs['kpis']}"
    else:
        if "ì„ì›" in u: prefs["audience"]="ì„ì›"; msg += "ì„ì›ìš© ìš”ì•½ ìœ„ì£¼ë¡œ êµ¬ì„±í• ê²Œìš”. "
        if "ì‹¤ë¬´" in u: prefs["audience"]="ì‹¤ë¬´"; msg += "ì‹¤ë¬´ìš© ìƒì„¸ì§€í‘œ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±í• ê²Œìš”. "
        if "ê°„ê²°" in u: prefs["tone"]="ê°„ê²°"; msg += "ê°„ê²°í•œ ì„œìˆ ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤. "
        if "ìƒì„¸" in u: prefs["tone"]="ìƒì„¸"; msg += "ìƒì„¸í•œ ì„œìˆ ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤. "
        if "ppt" in u or "íŒŒì›Œí¬ì¸íŠ¸" in u or "ìŠ¬ë¼ì´ë“œ" in u: prefs["outputs"]["ppt"] = True
        if "word" in u or "docx" in u or "ì›Œë“œ" in u: prefs["outputs"]["docx"] = True
        if "excel" in u or "ì—‘ì…€" in u or "xlsx" in u: prefs["outputs"]["excel"] = True
        if "markdown" in u or "md" in u: prefs["outputs"]["md"] = True
        msg += "ì„¤ì • ë°˜ì˜ ì™„ë£Œ! '/audience ì„ì›', '/tone ìƒì„¸', '/out ppt,word', '/kpi ë§¤ì¶œ,ì „í™˜ìœ¨'ì²˜ëŸ¼ë„ ì§€ì‹œí•  ìˆ˜ ìˆì–´ìš”."
    return msg

# ---------- ìœ í‹¸ ----------
def _y_axis_label_and_format(histnorm):
    if histnorm in (None, "count"): return "ê°œìˆ˜", ",.0f", None, "none"
    if histnorm == "percent": return "ë°±ë¶„ìœ¨(%)", ".1f", "%", "none"
    return "í™•ë¥ ë°€ë„", ".3f", None, "none"

# ---------- ë¶„ì„ + ì°¨íŠ¸ + ì„¤ëª… ìˆ˜ì§‘ ----------
def render_excel(file, file_name, prefs):
    df = pd.read_excel(file)
    st.subheader(f"ğŸ“Š {file_name} ë¶„ì„ ê²°ê³¼")

    # ì¶”ì²œ í”Œëœ
    plan = recommend_plan(df)
    with st.expander("ğŸ” ì¶”ì²œ ë³´ê³ ì„œ í”Œëœ", expanded=True):
        st.markdown(_humanize_plan(plan))
        if use_ollama:
            one_liner = _ollama_generate(
                ollama_base, ollama_model,
                "ë‹¤ìŒ ì¶”ì²œ í”Œëœì„ í•œêµ­ì–´ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”(ì¡´ëŒ“ë§): " + str(plan)
            )
            st.caption("ğŸ§  ìë™ ìš”ì•½: " + one_liner)

    # ìœ„ì ¯ key ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•œ prefix
    safe_name = file_name.replace("/", "_").replace("\\", "_")
    plan = _plan_editor(plan, key_prefix=f"plan_{safe_name}")

    # Ollama ê°œìš”
    overview_text = ""
    if use_ollama:
        prompt = (
            "ë‹¤ìŒ ë°ì´í„°ì˜ ì»¬ëŸ¼ê³¼ ì¶”ì²œ í”Œëœì„ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ê°„ê²°í•œ ë³´ê³ ì„œ ê°œìš”ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
            f"- ëŒ€ìƒ: {prefs['audience']}\n- ì–´ì¡°: {prefs['tone']}\n"
            f"- ì»¬ëŸ¼: {list(df.columns)}\n- ì¶”ì²œí”Œëœ: {plan}\n"
            "2~4ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ íë¦„(ì£¼ìš” ì§€í‘œ, ì¶”ì„¸, ë¹„êµ)ì„ ì œì•ˆí•´ ì£¼ì„¸ìš”."
        )
        overview_text = _ollama_generate(ollama_base, ollama_model, prompt)
        with st.expander("ğŸ—’ï¸ ìë™ ê°œìš”", expanded=True):
            st.write(overview_text)

    chart_images = []
    chart_explanations = {}

    # ê¸°ë³¸ í†µê³„
    st.write("âœ… ë°ì´í„° ìš”ì•½")
    try:
        st.markdown(df.describe(include="all").to_markdown())
    except Exception:
        st.text(df.describe(include="all").to_string())

    # ---- ì‹œê³„ì—´ ----
    if prefs["sections"]["timeseries"] and plan["timeseries"]:
        for (dcol, ncol) in plan["timeseries"]:
            try:
                tdf = df[[dcol, ncol]].dropna()
                tdf[dcol] = pd.to_datetime(tdf[dcol], errors="coerce"); tdf = tdf.dropna().sort_values(dcol)
                title = f"{file_name}<br>{ncol} - ì‹œê³„ì—´({dcol})"
                fig = px.line(tdf, x=dcol, y=ncol, markers=True)
                _style_plotly(fig, title=title)
                st.plotly_chart(fig, use_container_width=True)

                exp = ""
                if use_ollama:
                    p = (f"ì‹œê³„ì—´ ê·¸ë˜í”„ë¥¼ 2~3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”. ëŒ€ìƒ:{prefs['audience']} ì–´ì¡°:{prefs['tone']} "
                         f"ë°ì´í„°ì…‹:{file_name} x:{dcol} y:{ncol}. ì£¼ìš” ì¶”ì„¸/í”¼í¬/ë³€ë™ì„ ì–¸ê¸‰í•˜ì„¸ìš”.")
                    exp = _ollama_generate(ollama_base, ollama_model, p)
                    with st.expander(f"ğŸ—’ï¸ {ncol} ì‹œê³„ì—´ ì„¤ëª…", expanded=False):
                        st.write(exp)
                png = _fig_to_png_bytes(fig) or _mpl_hist_png(tdf[ncol], f"{file_name} Â· {ncol} ë¶„í¬(ëŒ€ì²´)", ncol, 20)
                chart_images.append((f"{ncol} ì‹œê³„ì—´", png))
                chart_explanations[f"{ncol} ì‹œê³„ì—´"] = exp
            except Exception:
                pass

    # ---- ìˆ«ìí˜• ë¶„í¬ ----
    for col in plan["numeric_dists"]:
        histnorm = y_scale
        if show_kde and histnorm in ("count", None): histnorm = "probability density"
        title = f"{file_name}<br>{col} ë¶„í¬"
        fig = px.histogram(df, x=col,
                           nbins=nbins if BIN_MODE=="ê°œìˆ˜ ì§€ì •" else None,
                           color_discrete_sequence=["#4C78A8"],
                           histnorm=None if histnorm=="count" else histnorm)
        if BIN_MODE == "ê°„ê²© ì§€ì •" and binsize and binsize>0:
            fig.update_traces(xbins=dict(size=binsize))
        fig.update_traces(marker_line_color="white", marker_line_width=1, opacity=0.9)
        fig.update_layout(bargap=bargap, bargroupgap=0.06)
        y_label, y_tickformat, y_suffix, expfmt = _y_axis_label_and_format(histnorm)
        fig.update_xaxes(title_text=col)
        fig.update_yaxes(title_text=y_label, tickformat=y_tickformat,
                         ticksuffix=(y_suffix or ""), showexponent="none", exponentformat=expfmt)
        _style_plotly(fig, title=title)

        if show_kde:
            vals = df[col].dropna().values
            xs, ys = _try_kde(vals)
            if xs is not None and ys is not None:
                fig.add_scatter(x=xs, y=ys, mode="lines", name="KDE", line=dict(color="#E45756", width=2))
        st.plotly_chart(fig, use_container_width=True)

        exp = ""
        if use_ollama:
            note = " (í•µì‹¬ KPI)" if col in prefs["kpis"] else ""
            prompt = (
                f"íˆìŠ¤í† ê·¸ë¨ í•´ì„¤{note}: ë°ì´í„°ì…‹:{file_name}, ì»¬ëŸ¼:{col}, ë‹¨ìœ„:{y_label}. "
                "ì¹˜ìš°ì¹¨/ë²”ìœ„/ì´ìƒì¹˜ë¥¼ 2~3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°íˆ ì„¤ëª…í•˜ê³ , ì—…ë¬´ ì¸ì‚¬ì´íŠ¸ 1ë¬¸ì¥ ì œì•ˆ(ì¡´ëŒ“ë§)."
            )
            exp = _ollama_generate(ollama_base, ollama_model, prompt)
            with st.expander(f"ğŸ—’ï¸ {col} ë¶„í¬ ì„¤ëª…", expanded=False): st.write(exp)

        png = _fig_to_png_bytes(fig)
        if png is None:
            fallback_bins = nbins if (BIN_MODE=="ê°œìˆ˜ ì§€ì •" and nbins) else 20
            png = _mpl_hist_png(df[col], f"{file_name} Â· {col} ë¶„í¬", col, bins=fallback_bins)
        chart_images.append((f"{col} ë¶„í¬", png))
        chart_explanations[f"{col} ë¶„í¬"] = exp

    # ---- ë²”ì£¼í˜• ë¶„í¬ ----
    if "categoricals" in plan and plan["categoricals"]:
        for col in plan["categoricals"]:
            vc = df[col].astype(str).value_counts().head(15)
            title = f"{file_name}<br>{col} ìƒìœ„ ë¹ˆë„"
            fig = px.bar(x=vc.index, y=vc.values, text=vc.values, labels={"x": col, "y": "ê°œìˆ˜"},
                         color_discrete_sequence=["#4C78A8"])
            _style_plotly(fig, title=title)
            fig.update_traces(textposition="outside"); fig.update_layout(yaxis_title="ê°œìˆ˜")
            st.plotly_chart(fig, use_container_width=True)

            exp = ""
            if use_ollama:
                prompt = (f"ë§‰ëŒ€ê·¸ë˜í”„ í•´ì„¤: ë°ì´í„°ì…‹:{file_name}, ë²”ì£¼:{col}, ìƒìœ„ í•­ëª©ê³¼ í¸ì¤‘ì„ 2ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ê³  "
                          f"ì—…ë¬´ì  ì‹œì‚¬ì ì„ 1ë¬¸ì¥ ì œì•ˆí•´ ì£¼ì„¸ìš”(ì¡´ëŒ“ë§).")
                exp = _ollama_generate(ollama_base, ollama_model, prompt)
                with st.expander(f"ğŸ—’ï¸ {col} ë²”ì£¼ ì„¤ëª…", expanded=False): st.write(exp)

            png = _fig_to_png_bytes(fig) or _mpl_hist_png(pd.Series(vc.values), f"{col} ë¹ˆë„(ëŒ€ì²´)", "ë¹ˆë„", 15)
            chart_images.append((f"{col} ë²”ì£¼", png))
            chart_explanations[f"{col} ë²”ì£¼"] = exp

    # ---- ìƒê´€ê´€ê³„ ----
    if prefs["sections"]["correlation"] and plan["correlation"]:
        num_cols = df.select_dtypes(include="number").columns
        corr = df[num_cols].corr(numeric_only=True)
        z = corr.values; x = corr.columns.tolist(); y = corr.columns.tolist()
        ann = corr.round(2).values
        heat = ff.create_annotated_heatmap(z=z, x=x, y=y, annotation_text=ann,
                                           colorscale="RdBu", showscale=True, reversescale=True)
        heat.update_coloraxes(colorbar_title="ìƒê´€ê³„ìˆ˜")
        _style_plotly(heat, title=f"{file_name}<br>ìˆ«ìí˜• ìƒê´€ê´€ê³„")
        st.plotly_chart(heat, use_container_width=True)

        exp = ""
        if use_ollama:
            pairs = []
            for i in range(len(x)):
                for j in range(i+1, len(y)):
                    pairs.append((x[i], y[j], float(corr.iloc[i,j])))
            pairs_sorted = sorted(pairs, key=lambda t: abs(t[2]), reverse=True)[:5]
            prompt = (f"ìƒê´€ íˆíŠ¸ë§µ í•´ì„¤: ë°ì´í„°ì…‹:{file_name}, ìƒìœ„ìŒ:{pairs_sorted}. "
                      "ìœ ì˜ë¯¸í•œ ì–‘/ìŒì˜ ìƒê´€ê³¼ ì£¼ì˜ì  2~3ë¬¸ì¥, í™œìš© ì œì•ˆ 1ë¬¸ì¥ì„ í•œêµ­ì–´ ì¡´ëŒ“ë§ë¡œ.")
            exp = _ollama_generate(ollama_base, ollama_model, prompt)
            with st.expander("ğŸ—’ï¸ ìƒê´€ê´€ê³„ ì„¤ëª…", expanded=False): st.write(exp)

        png = _fig_to_png_bytes(heat) or _mpl_corr_png(corr, f"{file_name} Â· ìˆ«ìí˜• ìƒê´€ê´€ê³„")
        chart_images.append(("ìˆ«ìí˜• ìƒê´€ê´€ê³„", png))
        chart_explanations["ìˆ«ìí˜• ìƒê´€ê´€ê³„"] = exp

    # ì‚¬ëŒ ì¹œí™” í”Œëœ í…ìŠ¤íŠ¸ ë°˜í™˜(ë³´ê³ ì„œ ê°œìš”ì— í¬í•¨ ê°€ëŠ¥)
    plan_md_text = _humanize_plan(plan)
    return df, chart_images, chart_explanations, overview_text, plan_md_text

# ---------- ë‚´ë³´ë‚´ê¸° ----------
def make_ppt_report(title: str, charts: dict, explanations: dict, overview_text: str) -> bytes:
    prs = Presentation()
    slide = prs.slides.add_slide(prs.slide_layouts[0])
    slide.shapes.title.text = title
    slide.placeholders[1].text = f"ìë™ ìƒì„± Â· {datetime.now().strftime('%Y-%m-%d %H:%M')}"

    if overview_text:
        s = prs.slides.add_slide(prs.slide_layouts[5])
        s.shapes.title.text = "ìš”ì•½ ê°œìš”"
        tx = s.shapes.add_textbox(PptxInches(0.8), PptxInches(1.5), PptxInches(8.4), PptxInches(3.6))
        tf = tx.text_frame; tf.clear()
        p = tf.paragraphs[0]; p.text = overview_text; p.font.size = Pt(16)

    for dataset_name, items in charts.items():
        s = prs.slides.add_slide(prs.slide_layouts[5]); s.shapes.title.text = f"ğŸ“¦ {dataset_name}"
        for title, png_bytes in items:
            slide = prs.slides.add_slide(prs.slide_layouts[5])
            slide.shapes.title.text = title
            if png_bytes:
                left = PptxInches(0.6); top = PptxInches(1.2); width = PptxInches(8.6)
                slide.shapes.add_picture(io.BytesIO(png_bytes), left, top, width=width)
            exp = explanations.get(dataset_name, {}).get(title, "")
            if exp:
                tx = slide.shapes.add_textbox(PptxInches(0.6), PptxInches(5.7), PptxInches(8.6), PptxInches(1.6))
                tf = tx.text_frame; tf.clear()
                p = tf.paragraphs[0]; p.text = exp; p.font.size = Pt(14); p.alignment = PP_ALIGN.LEFT

    out = io.BytesIO(); prs.save(out); return out.getvalue()

def make_word_report(title: str, dfs: list[pd.DataFrame], texts: list[str],
                     charts: dict, explanations: dict, overview_text: str) -> bytes:
    doc = Document()
    doc.add_heading(title, level=1)
    doc.add_paragraph(f"ìë™ ìƒì„± Â· {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    if overview_text:
        doc.add_heading("ìš”ì•½ ê°œìš”", level=2); doc.add_paragraph(overview_text)

    for i, df in enumerate(dfs, start=1):
        doc.add_heading(f"ë°ì´í„°ì…‹ {i} ìš”ì•½", level=2)
        desc = df.describe(include="all")
        table = doc.add_table(rows=1 + len(desc.index), cols=1 + len(desc.columns))
        table.style = "Light List Accent 1"
        hdr = table.rows[0].cells; hdr[0].text = ""
        for j, col in enumerate(desc.columns, start=1): hdr[j].text = str(col)
        for r_idx, idx_name in enumerate(desc.index, start=1):
            row = table.rows[r_idx].cells; row[0].text = str(idx_name)
            for c_idx, col in enumerate(desc.columns, start=1):
                val = desc.loc[idx_name, col]; row[c_idx].text = "" if pd.isna(val) else str(val)

    for ds_name, items in charts.items():
        doc.add_heading(f"ì°¨íŠ¸ - {ds_name}", level=2)
        for (title, png_bytes) in items:
            if png_bytes:
                doc.add_paragraph(f"â€¢ {title}")
                doc.add_picture(io.BytesIO(png_bytes), width=DocxInches(6.5))
                exp = explanations.get(ds_name, {}).get(title, "")
                if exp: doc.add_paragraph(exp)

    for i, txt in enumerate(texts, start=1):
        doc.add_heading(f"PDF ë¬¸ì„œ {i}", level=2)
        doc.add_paragraph(txt[:1500] + ("..." if len(txt) > 1500 else ""))

    out = io.BytesIO(); doc.save(out); return out.getvalue()

def make_excel_with_images(dfs, charts) -> bytes:
    out = io.BytesIO()
    with pd.ExcelWriter(out, engine="xlsxwriter") as writer:
        for i, df in enumerate(dfs, start=1):
            sheet_name = f"Data_{i}"
            df.to_excel(writer, sheet_name=sheet_name, index=False)
            ws = writer.sheets[sheet_name]
            for col_idx, col in enumerate(df.columns):
                max_len = max([len(str(col))] + [len(str(x)) for x in df[col].head(100).astype(str).tolist()])
                ws.set_column(col_idx, col_idx, min(max_len + 2, 40))
        chart_ws = writer.book.add_worksheet("Charts")
        for c in range(0, 24): chart_ws.set_column(c, c, 14)
        r, c, per_row, idx_in_row = 1, 1, 2, 0
        for ds_name, items in charts.items():
            chart_ws.write(r, c, f"ğŸ“¦ {ds_name}"); r += 1
            for (title, png_bytes) in items:
                if not png_bytes: continue
                chart_ws.write(r, c, f"â€¢ {title}")
                chart_ws.insert_image(r+1, c, "chart.png",
                                      {"image_data": io.BytesIO(png_bytes), "x_scale": 1.0, "y_scale": 1.0})
                idx_in_row += 1
                if idx_in_row % per_row == 0: r += 20; c = 1
                else: c += 8
            r += 22; c = 1; idx_in_row = 0
    return out.getvalue()

# ---------- PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ----------
def analyze_pdf(file, file_name):
    st.subheader(f"ğŸ“„ {file_name} í…ìŠ¤íŠ¸ ì¶”ì¶œ")
    text = ""
    with pdfplumber.open(file) as pdf:
        for page in pdf.pages:
            text += (page.extract_text() or "") + "\n"
    st.text_area("ğŸ“‘ ì¶”ì¶œëœ í…ìŠ¤íŠ¸", text, height=180)
    return text

# ================== ë©”ì¸ ==================
all_dfs, all_texts = [], []
all_charts: dict[str, list[tuple[str, bytes]]] = {}
all_explanations: dict[str, dict[str, str]] = {}
overview_by_dataset: dict[str, str] = {}
plan_text_by_dataset: dict[str, str] = {}

if uploaded_files:
    if len(st.session_state.messages) == 0:
        st.session_state.messages.append({"role":"assistant",
            "content":"ì–´ë–¤ ìŠ¤íƒ€ì¼ì˜ ë³´ê³ ì„œë¥¼ ì›í•˜ì„¸ìš”? ì˜ˆ) 'ì„ì›ìš©, PPT/Word ì¤‘ì‹¬, KPIëŠ” ë§¤ì¶œÂ·ì „í™˜ìœ¨, ìƒì„¸'\nëª…ë ¹í˜•: /audience ì„ì› /tone ìƒì„¸ /out ppt,word /kpi ë§¤ì¶œ,ì „í™˜ìœ¨"})

    for m in st.session_state.messages:
        with st.chat_message(m["role"]):
            st.write(m["content"])
    if prompt := st.chat_input("ë³´ê³ ì„œ ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”(ëª…ë ¹ì–´ ì§€ì›: /audience, /tone, /out, /kpi)"):
        st.session_state.messages.append({"role":"user","content":prompt})
        bot = chat_bot_reply(prompt)
        st.session_state.messages.append({"role":"assistant","content":bot})
        with st.chat_message("assistant"):
            st.write(bot)

    for file in uploaded_files:
        name = file.name
        if name.lower().endswith(("xlsx","xls")):
            df, imgs, exps, ov, plan_md_text = render_excel(file, name, st.session_state.prefs)
            all_dfs.append(df)
            all_charts[name] = imgs
            all_explanations[name] = exps  # dict(title->exp)
            overview_by_dataset[name] = ov
            plan_text_by_dataset[name] = plan_md_text
        elif name.lower().endswith("pdf"):
            text = analyze_pdf(file, name)
            all_texts.append(text)

    if st.button("ğŸ“¥ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"):
        merged_overview = "\n\n".join([t for t in list(overview_by_dataset.values()) + list(plan_text_by_dataset.values()) if t])

        if st.session_state.prefs["outputs"]["md"]:
            md = "# ğŸ¯ ì´ë²¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ\n\n"
            md += f"- ëŒ€ìƒ: {st.session_state.prefs['audience']} / ì–´ì¡°: {st.session_state.prefs['tone']}\n"
            md += "âœ¨ ìë™ ìƒì„±ëœ ìš”ì•½ ë¦¬í¬íŠ¸ì…ë‹ˆë‹¤.\n\n"
            if merged_overview:
                md += "## ê°œìš”\n" + merged_overview + "\n\n"
            for i, df in enumerate(all_dfs, start=1):
                md += f"## ë°ì´í„°ì…‹ {i} ìš”ì•½\n"
                try: md += df.describe(include="all").to_markdown() + "\n\n"
                except Exception: md += df.describe(include="all").to_string() + "\n\n"
            st.download_button("ğŸ“¥ Markdown ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ", data=md, file_name="event_report.md")

        if st.session_state.prefs["outputs"]["excel"]:
            xlsx = make_excel_with_images(all_dfs, all_charts)
            st.download_button("ğŸ“Š Excel ë³´ê³ ì„œ(ì°¨íŠ¸ ë‚´ì¥) ë‹¤ìš´ë¡œë“œ", data=xlsx, file_name="event_report_with_charts.xlsx")

        if st.session_state.prefs["outputs"]["ppt"]:
            ppt = make_ppt_report("ì´ë²¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ âœ¨", all_charts, all_explanations, merged_overview)
            st.download_button("ğŸ“½ PPT ë³´ê³ ì„œ(ì°¨íŠ¸Â·ì„¤ëª… í¬í•¨) ë‹¤ìš´ë¡œë“œ", data=ppt, file_name="event_report.pptx")

        if st.session_state.prefs["outputs"]["docx"]:
            docx = make_word_report("ì´ë²¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ âœ¨", all_dfs, all_texts, all_charts, all_explanations, merged_overview)
            st.download_button("ğŸ“ Word ë³´ê³ ì„œ(.docx) ë‹¤ìš´ë¡œë“œ", data=docx, file_name="event_report.docx")

        if any(len(v)>0 for v in all_charts.values()):
            zip_buf = io.BytesIO()
            with zipfile.ZipFile(zip_buf, "w", zipfile.ZIP_DEFLATED) as zf:
                for ds, items in all_charts.items():
                    safe = ds.replace("/", "_")
                    for i, (ctitle, png) in enumerate(items, start=1):
                        if not png: continue
                        zf.writestr(f"{safe}/chart_{i:02d}_{ctitle}.png", png)
            st.download_button("ğŸ–¼ ì°¨íŠ¸ PNG ë¬¶ìŒ(ZIP) ë‹¤ìš´ë¡œë“œ", data=zip_buf.getvalue(), file_name="charts.zip")
